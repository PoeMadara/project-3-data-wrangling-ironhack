
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def download_file_from_google_drive(file_id, destination):\n",
    "    \"\"\"\n",
    "    Downloads a file from Google Drive given its file ID.\n",
    "    \n",
    "    Parameters:\n",
    "        file_id (str): The ID of the file on Google Drive.\n",
    "        destination (str): The path where the file will be saved.\n",
    "    \"\"\"\n",
    "    URL = \"https://drive.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params={'id': file_id}, stream=True)\n",
    "    \n",
    "    # Check for confirmation token\n",
    "    token = None\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('confirm'):\n",
    "            token = value\n",
    "            break\n",
    "    \n",
    "    if token:\n",
    "        response = session.get(URL, params={'id': file_id, 'confirm': token}, stream=True)\n",
    "    \n",
    "    # Write file to destination\n",
    "    with open(destination, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    \n",
    "    print(f\"File downloaded and saved to {destination}\")\n",
    "\n",
    "# Google Drive file ID from the shared link\n",
    "file_id = '1PCZAdl7t2wyIapwoBAIDlPDsEU0xhiJJ'\n",
    "destination = 'downloaded_data_europe.csv'\n",
    "\n",
    "# Download the file\n",
    "download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv(destination)\n",
    "\n",
    "# Display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Remove rows that are completely empty\n",
    "df_cleaned = df.dropna(how='all')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "display(df_cleaned)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

     
     
    "'''import datacommons as dc\n",
    "import pandas as pd\n",
    "\n",
    "# Define the variables of interest\n",
    "variables = [\n",
    "    'Annual_Consumption_Electricity',\n",
    "    'Annual_Loss_Electricity',\n",
    "    'Annual_Emissions_CarbonDioxide_ElectricityGeneration',\n",
    "    'Annual_Emissions_CarbonDioxideEquivalent20YearGlobalWarmingPotential_ElectricityGeneration',\n",
    "    'Annual_Emissions_CarbonDioxideEquivalent100YearGlobalWarmingPotential_ElectricityGeneration'\n",
    "]\n",
    "\n",
    "# Get all European countries (place type: Country)\n",
    "places = dc.get_places_in('geoId/continent_Europe', 'Country')\n",
    "place_names = {}\n",
    "for place in places:\n",
    "    names = dc.get_property_values([place], 'name').get(place, [])\n",
    "    if names:\n",
    "        place_names[place] = names[0]\n",
    "    else:\n",
    "        place_names[place] = 'Unknown'\n",
    "\n",
    "# Initialize an empty DataFrame to store the data\n",
    "data = []\n",
    "\n",
    "# Fetch the latest data for each country and variable\n",
    "for place in places:\n",
    "    place_data = {}\n",
    "    place_data['placeDcid'] = place\n",
    "    place_data['placeName'] = place_names[place]\n",
    "    \n",
    "    # Fetch the latest value for each variable\n",
    "    for var in variables:\n",
    "        try:\n",
    "            series = dc.get_stat_series(place, var)\n",
    "            print(f\"Place: {place}, Variable: {var}, Series: {series}\")\n",
    "            \n",
    "            # Get the latest available date and value\n",
    "            if series:\n",
    "                latest_date = max(series.keys())\n",
    "                latest_value = series[latest_date]\n",
    "                place_data[f\"Date:{var}\"] = latest_date\n",
    "                place_data[f\"Value:{var}\"] = latest_value\n",
    "                place_data[f\"Source:{var}\"] = \"https://datacommons.org\"  # Adjust the source URL as needed\n",
    "            else:\n",
    "                place_data[f\"Date:{var}\"] = None\n",
    "                place_data[f\"Value:{var}\"] = None\n",
    "                place_data[f\"Source:{var}\"] = None\n",
    "        except Exception as e:\n",
    "            place_data[f\"Date:{var}\"] = None\n",
    "            place_data[f\"Value:{var}\"] = None\n",
    "            place_data[f\"Source:{var}\"] = None\n",
    "            print(f\"Error fetching data for {place} and variable {var}: {e}\")\n",
    "    \n",
    "    print(f\"Place data: {place_data}\")\n",
    "    data.append(place_data)\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows to verify the structure\n",
    "print(\"Data retrieved from DataCommons:\")\n",
    "print(df.head())\n",
    "\n",
    "# Clean the data by dropping rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Reset the index after cleaning\n",
    "df_clean.reset_index(inplace=True)\n",
    "\n",
    "# Optionally, save the cleaned dataset to a CSV file\n",
    "df_clean.to_csv('Cleaned_Europe_Energy_Data.csv', index=False)\n",
    "print(\"Cleaned data saved as 'Cleaned_Europe_Energy_Data.csv'.\")\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)    # Show all rows\n",
    "pd.set_option('display.max_columns', None) # Show all columns\n",
    "\n",
    "# Display the entire cleaned DataFrame\n",
    "print(\"Cleaned data:\")\n",
    "print(df_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "# Definir la URL de la API de Data Commons\n",
    "url = 'https://api.datacommons.org/place?utm_medium=explore&mprop=count&p=country:USA'\n",
    "\n",
    "# Realizar la solicitud GET\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar el estado de la respuesta\n",
    "if response.status_code == 200:\n",
    "    # Convertir la respuesta JSON en un diccionario\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "'''    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
